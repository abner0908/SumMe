#tokenizer
import nltk
from nltk.tokenize import wordpunct_tokenize

def tokenizer(str):
    
    
    return wordpunct_tokenize(str);
